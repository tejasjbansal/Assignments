hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar \
> -input /user/cloudera/word_count.txt \
> -output /user/cloudera/wordoutput \
> -mapper mapper.py \
> -reducer reducer.py \
> -file /home/cloudera/code/mapper.py \
> -file /home/cloudera/code/reducer.py
22/04/08 05:04:56 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
packageJobJar: [/home/cloudera/code/mapper.py, /home/cloudera/code/reducer.py] [/usr/jars/hadoop-streaming-2.6.0-cdh5.4.2.jar] /tmp/streamjob3385476610994105097.jar tmpDir=null
22/04/08 05:04:59 INFO client.RMProxy: Connecting to ResourceManager at quickstart.cloudera/127.0.0.1:8032
22/04/08 05:05:00 INFO client.RMProxy: Connecting to ResourceManager at quickstart.cloudera/127.0.0.1:8032
22/04/08 05:05:02 INFO mapred.FileInputFormat: Total input paths to process : 1
22/04/08 05:05:02 INFO mapreduce.JobSubmitter: number of splits:2
22/04/08 05:05:03 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1649343435305_0006
22/04/08 05:05:04 INFO impl.YarnClientImpl: Submitted application application_1649343435305_0006
22/04/08 05:05:04 INFO mapreduce.Job: The url to track the job: http://quickstart.cloudera:8088/proxy/application_1649343435305_0006/
22/04/08 05:05:04 INFO mapreduce.Job: Running job: job_1649343435305_0006
22/04/08 05:05:21 INFO mapreduce.Job: Job job_1649343435305_0006 running in uber mode : false
22/04/08 05:05:21 INFO mapreduce.Job:  map 0% reduce 0%
22/04/08 05:05:58 INFO mapreduce.Job:  map 100% reduce 0%
22/04/08 05:06:15 INFO mapreduce.Job:  map 100% reduce 100%
22/04/08 05:06:16 INFO mapreduce.Job: Job job_1649343435305_0006 completed successfully
22/04/08 05:06:17 INFO mapreduce.Job: Counters: 49
	File System Counters
		FILE: Number of bytes read=53
		FILE: Number of bytes written=351608
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=289
		HDFS: Number of bytes written=20
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=8744320
		Total time spent by all reduces in occupied slots (ms)=1845120
		Total time spent by all map tasks (ms)=68315
		Total time spent by all reduce tasks (ms)=14415
		Total vcore-seconds taken by all map tasks=68315
		Total vcore-seconds taken by all reduce tasks=14415
		Total megabyte-seconds taken by all map tasks=8744320
		Total megabyte-seconds taken by all reduce tasks=1845120
	Map-Reduce Framework
		Map input records=1
		Map output records=9
		Map output bytes=61
		Map output materialized bytes=65
		Input split bytes=224
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=65
		Reduce input records=9
		Reduce output records=3
		Spilled Records=18
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=780
		CPU time spent (ms)=6680
		Physical memory (bytes) snapshot=360140800
		Virtual memory (bytes) snapshot=2199420928
		Total committed heap usage (bytes)=142082048
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=65
	File Output Format Counters 
		Bytes Written=20
22/04/08 05:06:17 INFO streaming.StreamJob: Output directory: /user/cloudera/wordoutput



hdfs dfs -ls /user/cloudera/wordoutput
Found 2 items
-rw-r--r--   1 cloudera cloudera          0 2022-04-08 05:06 /user/cloudera/wordoutput/_SUCCESS
-rw-r--r--   1 cloudera cloudera         20 2022-04-08 05:06 /user/cloudera/wordoutput/part-00000




hdfs dfs -cat /user/cloudera/wordoutput/part-00000
dog	2
frog	2
jump	5